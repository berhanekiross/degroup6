{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jupyter lab --ip=0.0.0.0\n",
    "# start-master.sh\n",
    "# start-worker.sh spark://yash-kukrejade-6:7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "# from F import col, explode, lower, split\n",
    "\n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://yash-kukrejade-6:7077\") \\\n",
    "        .appName(\"BadWords\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\", 2)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# RDD API\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|            author|                body|             content|content_len|     id|      normalizedBody|           subreddit|subreddit_id|             summary|summary_len|   title|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|  raysofdarkmatter|I think it should...|I think it should...|        178|c69al3r|I think it should...|                math|    t5_2qh0n|Shifting seasonal...|          8|    null|\n",
      "|           Stork13|Art is about the ...|Art is about the ...|        148|c6a9nxd|Art is about the ...|               funny|    t5_2qh33|Personal opinions...|          4|    null|\n",
      "|     Cloud_dreamer|Ask me what I thi...|Ask me what I thi...|         76|c6acx4l|Ask me what I thi...|         Borderlands|    t5_2r8cd|insults and slack...|         73|    null|\n",
      "|     NightlyReaper|In Mechwarrior On...|In Mechwarrior On...|        213|c8onqew|In Mechwarrior On...|            gamingpc|    t5_2sq2y|Yes, Joysticks in...|         19|    null|\n",
      "|    NuffZetPand0ra|You are talking a...|You are talking a...|        404|c6acxvc|You are talking a...|              Diablo|    t5_2qore|Class only items ...|          7|D2 help?|\n",
      "|beatlecreedcabaret|All but one of my...|All but one of my...|        130|c6ahuc4|All but one of my...|   RedditLaqueristas|    t5_2se5q|      OPI Nail Envy!|          3|    null|\n",
      "|      nobodysdiary|I could give a sh...|I could give a sh...|        156|c6aggux|I could give a sh...|               apple|    t5_2qh1f|I don't drive lik...|         18|    null|\n",
      "|          chrom_ed|So you're saying ...|So you're saying ...|        134|c6agxtv|So you're saying ...|               apple|    t5_2qh1f|you don't seem to...|          9|    null|\n",
      "|      gadzookfilms|I love this idea ...|I love this idea ...|        126|c6asb7p|I love this idea ...|RedditFilmsProduc...|    t5_2v33h|How we make money...|          9|    null|\n",
      "|      iamacannibal|Theres an entire ...|Theres an entire ...|        181|c6aveyw|Theres an entire ...|       AbandonedPorn|    t5_2sh6t|I'll try and get ...|         25|    null|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+\n",
      "|      normalizedBody|\n",
      "+--------------------+\n",
      "|I think it should...|\n",
      "|Art is about the ...|\n",
      "|Ask me what I thi...|\n",
      "|In Mechwarrior On...|\n",
      "|You are talking a...|\n",
      "|All but one of my...|\n",
      "|I could give a sh...|\n",
      "|So you're saying ...|\n",
      "|I love this idea ...|\n",
      "|Theres an entire ...|\n",
      "|FALSE. Evidence: ...|\n",
      "|If the number of ...|\n",
      "|Yeah, but most fo...|\n",
      "|As an entrepreneu...|\n",
      "|i guess the way I...|\n",
      "|Didn't they lose ...|\n",
      "|You probably won'...|\n",
      "|To simply say tha...|\n",
      "|This picture does...|\n",
      "|And that is, hand...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# root\n",
    "#  |-- author: string (nullable = true) \n",
    "#  |-- body: string (nullable = true)\n",
    "#  |-- content: string (nullable = true)\n",
    "#  |-- content_len: long (nullable = true)\n",
    "#  |-- id: string (nullable = true)\n",
    "#  |-- normalizedBody: string (nullable = true)\n",
    "#  |-- subreddit: string (nullable = true)\n",
    "#  |-- subreddit_id: string (nullable = true)\n",
    "#  |-- summary: string (nullable = true)\n",
    "#  |-- summary_len: long (nullable = true) \n",
    "#  |-- title: string (nullable = true)\n",
    "\n",
    "reddit_data = spark_session.read.json(\"/home/ubuntu/sample_2000.json\")\n",
    "# Print the first 10 lines of the DataFrame\n",
    "reddit_data.show(10)\n",
    "reddit_data = reddit_data.drop(\n",
    "    *[\n",
    "        \"content_len\",\n",
    "        \"summary_len\",\n",
    "        \"id\",\n",
    "        \"subreddit_id\",\n",
    "        \"body\",\n",
    "        \"content\",\n",
    "        \"summary\",\n",
    "        \"title\",\n",
    "        \"subreddit\",\n",
    "        \"author\"\n",
    "    ]\n",
    ")\n",
    "reddit_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# https://www.cs.cmu.edu/~biglou/resources/bad-words.txt\n",
    "bad_words = spark_context.textFile(\"/home/ubuntu/bad_words.txt\")\n",
    "# bad_words = spark_session.createDataFrame(bad_words, ['bad_words'])\n",
    "bad_words = bad_words.filter(lambda x: x != '').collect()\n",
    "# print(bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit_data = reddit_data.withColumn(\"splited_words\", F.split(\"normalizedBody\", ' '))\n",
    "reddit_data = reddit_data.filter(F.col('normalizedBody').rlike('|'.join(bad_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|bad_word|count|\n",
      "+--------+-----+\n",
      "|    shit|  176|\n",
      "| fucking|  170|\n",
      "|    fuck|  127|\n",
      "|     god|  103|\n",
      "|    kill|   90|\n",
      "|     kid|   87|\n",
      "|   black|   86|\n",
      "|     sex|   80|\n",
      "|  stupid|   71|\n",
      "|     ass|   66|\n",
      "|    damn|   63|\n",
      "|   fight|   59|\n",
      "|   girls|   56|\n",
      "|     fat|   54|\n",
      "|   death|   52|\n",
      "|     gun|   50|\n",
      "|    hell|   49|\n",
      "|     gay|   49|\n",
      "|  killed|   46|\n",
      "|  fucked|   45|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read bad words from text file\n",
    "bad_words = spark_session.read.text(\"/home/ubuntu/bad_words.txt\") \\\n",
    "    .filter(F.col(\"value\") != \"\") \\\n",
    "    .select(F.col(\"value\").alias(\"bad_word\"))\n",
    "\n",
    "# Extract words from comments and explode them\n",
    "words = reddit_data.select(F.explode(F.split(F.lower(F.col(\"normalizedBody\")), \"\\\\s+\")).alias(\"word\"))\n",
    "\n",
    "# Filter out bad words\n",
    "bad_words_counts = words.join(bad_words, words.word == bad_words.bad_word, \"left_outer\") \\\n",
    "    .filter(F.col(\"bad_word\").isNotNull()) \\\n",
    "    .groupBy(\"bad_word\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "\n",
    "# # Show bad words counts\n",
    "bad_words_counts.show()\n",
    "\n",
    "# Stop SparkSession\n",
    "spark_session.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
